{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Project Proposal\n",
    "\n",
    "## Authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dhruv Patel: Analysis, Software, Data curation, \n",
    "- Elthor Olivas Corral: Experimental investigation, Analysis, Writing - original draft\n",
    "- Syrine Mekni: Project administration, Conceptualization, Background research, Writing - review & editing\n",
    "- Yen-Hsianf Chiu: Methodology, Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How has the distribution of ChatGPT prompts shifted from primarily task-based and informational uses toward more interpersonal and intrapersonal uses (e.g., emotional reflection and relationship interpretation) between April 2023 and May 2024, as measured by topic modeling and sentiment analysis of public ChatGPT conversation data?\n",
    "\n",
    "In this study, time (April 2023–May 2024) is treated as the independent variable and prompt type (task-based vs interpersonal/intrapersonal) as the dependent variable, with prompt length and system-generated messages controlled for, and the analysis grounded in prior literature on human–AI interaction and the social use of conversational agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversational artificial intelligence has evolved significantly since its early origins, when systems were designed primarily for instructional or task-oriented interactions. Early conversational agents such as ELIZA were created to simulate dialogue through simple pattern matching, offering the appearance of conversation without genuine understanding and serving mainly as demonstrations of human–computer interaction rather than functional assistants.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) For decades, most chatbots remained limited to narrow informational tasks, customer service automation, or scripted question answering. In contrast, modern large language models such as ChatGPT have rapidly gained widespread adoption and are now used by millions of people for a diverse range of purposes, extending well beyond information retrieval to include brainstorming, emotional reflection, and relationship-oriented conversations.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) This noticeable shift from primarily task-based support toward more social and emotionally expressive interaction motivates the present study, which examines how the distribution of ChatGPT prompt types has changed between April 2023 and May 2024 using topic modeling and sentiment analysis of public conversation data.\n",
    "\n",
    "A growing body of research in human–AI interaction has examined the emotional and social dimensions of chatbot use, finding that users often engage conversational agents in ways that resemble interpersonal relationships. For example, Fitzpatrick et al. (2017) studied interactions with a fully automated mental-health chatbot and found that users frequently disclosed personal emotions and reported feeling supported, despite knowing the system was not human.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) Similarly, studies of social chatbots such as XiaoIce have shown that users engage in long-term, emotionally expressive conversations and may attribute relational qualities such as empathy and companionship to the system, indicating forms of parasocial or quasi-social interaction.<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4) More recent work in Proceedings of the ACM on Human–Computer Interaction demonstrates that framing chatbot interactions as ephemeral increases users' willingness to disclose intimate information, reinforcing the idea that conversational agents are often perceived as non-judgmental confidants; however, these findings typically come from specific applications or controlled study settings rather than large-scale, open-ended usage logs.<a name=\"cite_ref-5\"></a>[<sup>5</sup>](#cite_note-5)\n",
    "\n",
    "Beyond small-scale or domain-specific studies, recent research has begun to examine how human–AI interaction evolves using large-scale conversational datasets. For example, research using the WildChat dataset analyzes over one million real-world ChatGPT conversations to characterize how users engage with conversational AI systems across a wide range of intents, demonstrating substantial diversity in prompt types and interaction styles at scale.<a name=\"cite_ref-6\"></a>[<sup>6</sup>](#cite_note-6) Related large-scale studies of language model usage similarly suggest that as models become more capable and widely deployed, user interactions diversify beyond narrowly task-oriented queries toward more exploratory, creative, and socially oriented uses. However, much of this work focuses on broad usage characterization or safety concerns rather than explicitly examining how the distribution of prompt types changes over time. In addition, some longitudinal analyses aggregate interactions across broad time spans or model versions, limiting their ability to isolate shorter-term temporal shifts in interpersonal versus task-based usage.\n",
    "\n",
    "Taken together, prior research establishes that conversational agents can elicit emotional disclosure and interpersonal engagement, but it does not directly test whether interpersonal and intrapersonal uses of ChatGPT are becoming more prevalent relative to task-based and informational uses within a recent, well-defined time window. Our project addresses this gap by using the WildChat dataset to examine whether the distribution of ChatGPT prompt types has shifted between April 2023 and May 2024 within a real-world sample of public interactions. By applying topic modeling and sentiment analysis to distinguish task-based prompts from interpersonal and intrapersonal prompts, we extend prior research on emotional disclosure and social uses of chatbots to a large-scale, temporally sensitive setting. This allows us to test whether social and self-reflective uses of ChatGPT are becoming more prevalent over time, rather than simply documenting that such uses exist.\n",
    "\n",
    "**References:**\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Weizenbaum, J. (1966). ELIZA—a computer program for the study of natural language communication between man and machine. *Communications of the ACM*, 9(1), 36-45. https://dl.acm.org/doi/10.1145/365153.365168\n",
    "\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) OpenAI. (2023). Introducing ChatGPT. https://openai.com/index/chatgpt/\n",
    "\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Fitzpatrick, K. K., Darcy, A., & Vierhile, M. (2017). Delivering cognitive behavior therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): A randomized controlled trial. *JMIR Mental Health*, 4(2), e19. https://mental.jmir.org/2017/2/e19/\n",
    "\n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Shum, H., He, X., & Li, D. (2018). From Eliza to XiaoIce: Challenges and opportunities with social chatbots. *Frontiers of Information Technology & Electronic Engineering*, 19(11), 1359-1384. http://link.springer.com/article/10.1631/FITEE.1800578\n",
    "\n",
    "5. <a name=\"cite_note-5\"></a> [^](#cite_ref-5) Cox, S. R., Jacobsen, R. M., & van Berkel, N. (2025). The impact of a chatbot's ephemerality-framing on self-disclosure. *Proceedings of the ACM on Human-Computer Interaction*, 9(CSCW1), Article 17. https://dl.acm.org/doi/10.1145/3719160.3736617\n",
    "\n",
    "6. <a name=\"cite_note-6\"></a> [^](#cite_ref-6) Zhao, J., Choi, Y., Smith, N. A., et al. (2024). WildChat: 1M ChatGPT interaction logs in the wild [Dataset]. Allen Institute for AI. https://wildchat.allen.ai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that between April 2023 and May 2024, the proportion of interpersonal and intrapersonal ChatGPT prompts will increase relative to task-based and informational prompts. This expectation is based on prior research showing that as conversational AI systems become more capable, familiar, and designed to be pleasant, approachable, and human-like, users increasingly disclose emotions, seek support, and treat them as confidants. Building on evidence that conversational AI use has diversified beyond narrowly task-oriented queries, we expect social and self-reflective interactions with ChatGPT to become more prevalent over time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Dataset\n",
    "\n",
    "The ideal dataset for this project would include:\n",
    "\n",
    "**Variables:** User prompts (text), timestamp, conversation context, user demographics (age, location, language), prompt intent/category, sentiment indicators, conversation length, and ChatGPT model version used.\n",
    "\n",
    "**Observations:** At minimum, several thousand conversations per month across the April 2023–May 2024 period to detect temporal trends. Ideally, 50,000+ conversations to ensure statistical power for topic modeling and sentiment analysis.\n",
    "\n",
    "**Collection:** Data would be collected through opt-in user consent from ChatGPT users willing to share anonymized conversation logs for research purposes, with explicit agreement to research use and privacy protections.\n",
    "\n",
    "**Storage/Organization:** Data would be stored in a structured database with each row representing a single prompt, including fields for conversation ID, timestamp, prompt text, response text, metadata (model version, language), and derived features (topic labels, sentiment scores). Conversations would be organized chronologically and indexed by conversation ID for multi-turn analysis.\n",
    "\n",
    "### Real Dataset\n",
    "\n",
    "**WildChat: 1M ChatGPT Interaction Logs in the Wild**\n",
    "\n",
    "The WildChat dataset is publicly available through Hugging Face at https://huggingface.co/datasets/allenai/WildChat and requires no special permission to access. This dataset contains over one million real-world conversations between users and ChatGPT collected between April 2023 and May 2024, making it ideal for our temporal analysis. The dataset includes user prompts, assistant responses, timestamps, conversation metadata, and language information. Key variables we will use include the prompt text (for topic modeling), timestamps (to track changes over time), and conversation structure (to distinguish user prompts from system messages). This dataset allows us to analyze actual usage patterns rather than relying on survey data or controlled experiments, though we acknowledge it may not include demographic information about users and may have selection biases toward users comfortable sharing conversations publicly. Compared with our ideal dataset, WildChat does not include detailed user demographics or pre‑labeled prompt intent categories, and it reflects only users who consented to share their conversations publicly. However, it closely matches our temporal and scale requirements and provides rich textual and metadata fields that allow us to approximate our ideal variables through topic modeling and sentiment analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "### A. Data Collection\n",
    "\n",
    "The WildChat dataset contains ChatGPT conversations released for research, but many users may not have anticipated a detailed public analysis of their prompts. We therefore treat consent as limited and focus only on aggregate patterns, avoiding any attempt to surface or re‑identify individuals. The dataset is likely biased toward English‑speaking, tech‑comfortable users, so we will emphasize that our findings describe this subset of usage rather than all ChatGPT users. Because prior work shows that people sometimes disclose sensitive or personal information in such logs, we will avoid quoting highly sensitive prompts verbatim. We will paraphrase or use synthetic examples when illustrating categories.\n",
    "\n",
    "### B. Data Storage\n",
    "\n",
    "We will store WildChat locally using secure, access‑controlled storage and delete raw data after completing our analyses, retaining only aggregated statistics and code. Since the dataset is released as an anonymized research corpus, we cannot honor individual “right to be forgotten” requests, and we will not attempt any re‑identification.\n",
    "\n",
    "### C. Analysis\n",
    "\n",
    "Our analysis may miss important cultural, linguistic, and demographic perspectives because of who appears in WildChat, so we will explicitly discuss this limitation. When feasible, we will briefly check whether prompt types or sentiments differ across available metadata (e.g., country or language) and discuss how unequal representation or usage patterns might reflect or reinforce existing inequities rather than inherent traits of particular groups. We will present results honestly (clearly labeling filters, subsampling, and uncertainty) and avoid sensational or stigmatizing interpretations of specific prompt categories.\n",
    "\n",
    "### D. Modeling\n",
    "\n",
    "We are not building a deployed predictive model, but our use of topic modeling and sentiment analysis can still introduce bias. We will document how we choose topic numbers, sentiment tools, and label definitions, and acknowledge that these choices embed particular cultural assumptions about what counts as “positive,” “negative,” or “interpersonal.” If we introduce any automated classifiers for prompt type, we will note that they may misclassify some groups or topics, and interpret such outputs cautiously.\n",
    "\n",
    "### E. Deployment\n",
    "\n",
    "We will not deploy a system; results will be shared only as a research report. However, our findings could be repurposed in unintended ways, such as profiling “vulnerable” users or optimizing engagement with emotionally distressed people for commercial or surveillance purposes. To mitigate this, we will explicitly warn against using our results to target or exploit specific user groups and frame our work as aiming to understand patterns of use and inform safer, more supportive conversational AI design. Because our project examines whether emotional and interpersonal use is increasing over time, we recognize that framing such trends without context could contribute to narratives about user dependency or vulnerability. We will therefore interpret any observed increase cautiously and avoid implying that emotional engagement with AI is inherently beneficial or harmful.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Communication and Responsiveness:** Each team member will check and respond to messages on our agreed communication platform within 24 hours on weekdays. Important decisions will be discussed collectively in scheduled meetings.\n",
    "\n",
    "* **Respectful Collaboration:** Team members will provide constructive feedback respectfully, even when disagreeing. Conflicts will be addressed immediately via discussion, not ignored.\n",
    "\n",
    "* **Responsibility and Accountability:** Everyone is responsible for completing their assigned tasks by agreed deadlines. If a team member cannot meet a deadline, they will notify the team in advance and propose a solution.\n",
    "\n",
    "* **Documentation and Transparency:** All code, analysis, and notes will be shared in a central repository with clear version control. Any assumptions, decisions, or changes to methods will be recorded for transparency.\n",
    "\n",
    "* **Mutual Support and Learning:** Team members will assist one another in understanding methods, tools, or concepts as needed. We encourage knowledge sharing to ensure all members can contribute meaningfully to the project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date | Meeting Time | Completed Before Meeting | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/28 | 6 PM | Read COGS 108 expectations; review project requirements | Finalize communication channels; confirm research question and hypothesis; assign initial background research tasks |\n",
    "| 2/3 | 6 PM | Complete assigned background research; identify potential datasets | Review background research; discuss WildChat dataset access and structure; draft ethics considerations |\n",
    "| 2/4 | 6 PM | Finalize and review proposal draft | Submit project proposal; discuss data download and initial exploration plan; assign data wrangling tasks |\n",
    "| 2/11 | 6 PM | Download WildChat dataset; explore data structure | Review data characteristics; plan preprocessing pipeline (filtering by date, removing system messages, handling missing data) |\n",
    "| 2/14 | 6 PM | Complete data wrangling and cleaning; perform initial EDA | Review wrangling/EDA; finalize approach for topic modeling and sentiment analysis; assign analysis tasks |\n",
    "| 2/25 | 6 PM | Implement topic modeling (e.g., LDA) and sentiment analysis | Review analysis results; refine categorization of prompt types; complete project check-in |\n",
    "| 3/6 | 6 PM | Conduct temporal analysis of prompt type distribution | Discuss findings; create visualizations; begin drafting results and discussion sections |\n",
    "| 3/13 | 6 PM | Complete analysis; draft results, conclusion, and discussion | Review and edit full project; address any remaining limitations or ethical considerations |\n",
    "| 3/20 | Before 11:59 PM | Finalize all sections; proofread | Submit Final Project & Group Project Surveys |\n",
    "\n",
    "**Special Resources/Training Needed:** This project will require use of natural language processing libraries such as scikit-learn or gensim for topic modeling (LDA or similar), and NLTK or TextBlob for sentiment analysis. Team members unfamiliar with these tools will review relevant COGS 108 materials and online tutorials (e.g., scikit-learn documentation, topic modeling guides) before the analysis phase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
