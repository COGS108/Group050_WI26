{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Project Proposal\n",
    "\n",
    "## Authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dhruv Patel: Analysis, Software, Data curation, \n",
    "- Elthor Olivas Corral: Experimental investigation, Analysis, Writing - original draft\n",
    "- Syrine Mekni: Project administration, Conceptualization, Background research, Writing - review & editing\n",
    "- Yen-Hsianf Chiu: Methodology, Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How has the distribution of ChatGPT prompts shifted from primarily task-based and informational uses toward more interpersonal and intrapersonal uses (e.g., emotional reflection and relationship interpretation) between April 2023 and May 2024, as measured by topic modeling and sentiment analysis of public ChatGPT conversation data?\n",
    "\n",
    "In this study, time (April 2023–May 2024) is treated as the independent variable and prompt type (task-based vs interpersonal/intrapersonal) as the dependent variable, with prompt length and system-generated messages controlled for, and the analysis grounded in prior literature on human–AI interaction and the social use of conversational agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversational artificial intelligence has evolved significantly since its early origins, when systems were designed primarily for instructional or task-oriented interactions. Early conversational agents such as ELIZA were created to simulate dialogue through simple pattern matching, offering the appearance of conversation without genuine understanding and serving mainly as demonstrations of human–computer interaction rather than functional assistants.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) For decades, most chatbots remained limited to narrow informational tasks, customer service automation, or scripted question answering. In contrast, modern large language models such as ChatGPT have rapidly gained widespread adoption and are now used by millions of people for a diverse range of purposes, extending well beyond information retrieval to include brainstorming, emotional reflection, and relationship-oriented conversations.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) This noticeable shift from primarily task-based support toward more social and emotionally expressive interaction motivates the present study, which examines how the distribution of ChatGPT prompt types has changed between April 2023 and May 2024 using topic modeling and sentiment analysis of public conversation data.\n",
    "\n",
    "A growing body of research in human–AI interaction has examined the emotional and social dimensions of chatbot use, finding that users often engage conversational agents in ways that resemble interpersonal relationships. For example, Fitzpatrick et al. (2017) studied interactions with a fully automated mental-health chatbot and found that users frequently disclosed personal emotions and reported feeling supported, despite knowing the system was not human.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) Similarly, studies of social chatbots such as XiaoIce have shown that users engage in long-term, emotionally expressive conversations and may attribute relational qualities such as empathy and companionship to the system, indicating forms of parasocial or quasi-social interaction.<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4) More recent work in Proceedings of the ACM on Human–Computer Interaction demonstrates that framing chatbot interactions as ephemeral increases users' willingness to disclose intimate information, reinforcing the idea that conversational agents are often perceived as non-judgmental confidants; however, these findings typically come from specific applications or controlled study settings rather than large-scale, open-ended usage logs.<a name=\"cite_ref-5\"></a>[<sup>5</sup>](#cite_note-5)\n",
    "\n",
    "Beyond small-scale or domain-specific studies, recent research has begun to examine how human–AI interaction evolves using large-scale conversational datasets. For example, research using the WildChat dataset analyzes over one million real-world ChatGPT conversations to characterize how users engage with conversational AI systems across a wide range of intents, demonstrating substantial diversity in prompt types and interaction styles at scale.<a name=\"cite_ref-6\"></a>[<sup>6</sup>](#cite_note-6) Related large-scale studies of language model usage similarly suggest that as models become more capable and widely deployed, user interactions diversify beyond narrowly task-oriented queries toward more exploratory, creative, and socially oriented uses. However, much of this work focuses on broad usage characterization or safety concerns rather than explicitly examining how the distribution of prompt types changes over time. In addition, some longitudinal analyses aggregate interactions across broad time spans or model versions, limiting their ability to isolate shorter-term temporal shifts in interpersonal versus task-based usage.\n",
    "\n",
    "Taken together, prior research establishes that conversational agents can elicit emotional disclosure and interpersonal engagement, but it does not directly test whether interpersonal and intrapersonal uses of ChatGPT are becoming more prevalent relative to task-based and informational uses within a recent, well-defined time window. Our project addresses this gap by using the WildChat dataset to examine whether the distribution of ChatGPT prompt types has shifted between April 2023 and May 2024 within a real-world sample of public interactions. By applying topic modeling and sentiment analysis to distinguish task-based prompts from interpersonal and intrapersonal prompts, we extend prior research on emotional disclosure and social uses of chatbots to a large-scale, temporally sensitive setting. This allows us to test whether social and self-reflective uses of ChatGPT are becoming more prevalent over time, rather than simply documenting that such uses exist.\n",
    "\n",
    "**References:**\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Weizenbaum, J. (1966). ELIZA—a computer program for the study of natural language communication between man and machine. *Communications of the ACM*, 9(1), 36-45. https://dl.acm.org/doi/10.1145/365153.365168\n",
    "\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) OpenAI. (2023). Introducing ChatGPT. https://openai.com/index/chatgpt/\n",
    "\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Fitzpatrick, K. K., Darcy, A., & Vierhile, M. (2017). Delivering cognitive behavior therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): A randomized controlled trial. *JMIR Mental Health*, 4(2), e19. https://mental.jmir.org/2017/2/e19/\n",
    "\n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Shum, H., He, X., & Li, D. (2018). From Eliza to XiaoIce: Challenges and opportunities with social chatbots. *Frontiers of Information Technology & Electronic Engineering*, 19(11), 1359-1384. http://link.springer.com/article/10.1631/FITEE.1800578\n",
    "\n",
    "5. <a name=\"cite_note-5\"></a> [^](#cite_ref-5) Cox, S. R., Jacobsen, R. M., & van Berkel, N. (2025). The impact of a chatbot's ephemerality-framing on self-disclosure. *Proceedings of the ACM on Human-Computer Interaction*, 9(CSCW1), Article 17. https://dl.acm.org/doi/10.1145/3719160.3736617\n",
    "\n",
    "6. <a name=\"cite_note-6\"></a> [^](#cite_ref-6) Zhao, J., Choi, Y., Smith, N. A., et al. (2024). WildChat: 1M ChatGPT interaction logs in the wild [Dataset]. Allen Institute for AI. https://wildchat.allen.ai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that between April 2023 and May 2024, the proportion of interpersonal and intrapersonal ChatGPT prompts will increase relative to task-based and informational prompts. This expectation is based on prior research showing that as conversational AI systems become more capable, familiar, and designed to be pleasant, approachable, and human-like, users increasingly disclose emotions, seek support, and treat them as confidants. Building on evidence that conversational AI use has diversified beyond narrowly task-oriented queries, we expect social and self-reflective interactions with ChatGPT to become more prevalent over time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Dataset\n",
    "\n",
    "The ideal dataset for this project would include:\n",
    "\n",
    "**Variables:** User prompts (text), timestamp, conversation context, user demographics (age, location, language), prompt intent/category, sentiment indicators, conversation length, and ChatGPT model version used.\n",
    "\n",
    "**Observations:** At minimum, several thousand conversations per month across the April 2023–May 2024 period to detect temporal trends. Ideally, 50,000+ conversations to ensure statistical power for topic modeling and sentiment analysis.\n",
    "\n",
    "**Collection:** Data would be collected through opt-in user consent from ChatGPT users willing to share anonymized conversation logs for research purposes, with explicit agreement to research use and privacy protections.\n",
    "\n",
    "**Storage/Organization:** Data would be stored in a structured database with each row representing a single prompt, including fields for conversation ID, timestamp, prompt text, response text, metadata (model version, language), and derived features (topic labels, sentiment scores). Conversations would be organized chronologically and indexed by conversation ID for multi-turn analysis.\n",
    "\n",
    "### Real Dataset\n",
    "\n",
    "**WildChat: 1M ChatGPT Interaction Logs in the Wild**\n",
    "\n",
    "The WildChat dataset is publicly available through Hugging Face at https://huggingface.co/datasets/allenai/WildChat and requires no special permission to access. This dataset contains over one million real-world conversations between users and ChatGPT collected between April 2023 and May 2024, making it ideal for our temporal analysis. The dataset includes user prompts, assistant responses, timestamps, conversation metadata, and language information. Key variables we will use include the prompt text (for topic modeling), timestamps (to track changes over time), and conversation structure (to distinguish user prompts from system messages). This dataset allows us to analyze actual usage patterns rather than relying on survey data or controlled experiments, though we acknowledge it may not include demographic information about users and may have selection biases toward users comfortable sharing conversations publicly. Compared with our ideal dataset, WildChat does not include detailed user demographics or pre‑labeled prompt intent categories, and it reflects only users who consented to share their conversations publicly. However, it closely matches our temporal and scale requirements and provides rich textual and metadata fields that allow us to approximate our ideal variables through topic modeling and sentiment analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "### A. Data Collection\n",
    "\n",
    "- [X] **A.1 Informed consent**: The WildChat dataset contains publicly available conversations between users and LLMs. Users did not explicitly provide consent for research use, but the data was released for public research purposes. We acknowledge this as a potential concern and will ensure that our analysis avoids exposing individual users or their personal information.\n",
    "\n",
    "- [X] **A.2 Collection bias**: There may be selection biases in the dataset, such as overrepresentation of English-speaking users or users who are comfortable sharing publicly. We will note these limitations when interpreting results and acknowledge that our findings may not generalize to all ChatGPT users.\n",
    "\n",
    "- [X] **A.3 Limit PII exposure**: All analyses will focus on prompt types and sentiment rather than individual user identifiers. Any potentially identifying content will be anonymized or excluded from analysis and reporting.\n",
    "\n",
    "- [X] **A.4 Downstream bias mitigation**: Not directly applicable as we are performing descriptive analysis rather than predictive modeling. However, we will examine whether certain prompt types or sentiments are overrepresented and discuss potential biases.\n",
    "\n",
    "### B. Data Storage\n",
    "\n",
    "- [X] **B.1 Data security**: All WildChat data will be stored securely on encrypted internal storage with controlled access limited to project team members. We will follow best practices for data handling throughout the project.\n",
    "\n",
    "- [X] **B.2 Right to be forgotten**: Not directly applicable because data is anonymized and publicly released. Individual users cannot be identified to exercise this right.\n",
    "\n",
    "- [X] **B.3 Data retention plan**: We plan to delete downloaded datasets once analysis is completed and results documented, retaining only aggregated results and necessary documentation for reproducibility.\n",
    "\n",
    "### C. Analysis\n",
    "\n",
    "- [X] **C.1 Missing perspectives**: We acknowledge that our analysis does not capture all cultural, linguistic, or demographic perspectives. The dataset is likely biased toward English-speaking users and those comfortable with technology. We will explicitly note this limitation in our findings.\n",
    "\n",
    "- [X] **C.2 Dataset bias**: Potential biases, such as overrepresentation of certain prompt types, topics, or user populations, will be discussed in the limitations section. We will examine the distribution of languages and conversation types to characterize these biases.\n",
    "\n",
    "- [X] **C.3 Honest representation**: We commit to presenting visualizations and summary statistics that accurately reflect the underlying data, avoiding misleading interpretations or cherry-picking results that support our hypothesis.\n",
    "\n",
    "- [X] **C.4 Privacy in analysis**: No PII will be analyzed or displayed. Only prompt-level trends and aggregated statistics will be reported. Individual conversations will not be quoted in ways that could identify users.\n",
    "\n",
    "- [X] **C.5 Auditability**: Analysis scripts, methods, and preprocessing steps will be fully documented in our code repository with clear version control, making our analysis reproducible and transparent.\n",
    "\n",
    "### D. Modeling\n",
    "\n",
    "- [X] **D.1 Proxy discrimination**: Not applicable; we are not building a predictive model that could discriminate against protected groups.\n",
    "\n",
    "- [X] **D.2 Fairness across groups**: Not applicable to our descriptive analysis.\n",
    "\n",
    "- [X] **D.3 Metric selection**: Not applicable to our descriptive analysis.\n",
    "\n",
    "- [X] **D.4 Explainability**: Not applicable; we are using interpretable methods (topic modeling and sentiment analysis) rather than black-box models.\n",
    "\n",
    "- [X] **D.5 Communicate limitations**: Limitations, such as potential selection bias, dataset incompleteness, and inability to verify ground truth for prompt categorization, will be clearly communicated in the final report.\n",
    "\n",
    "### E. Deployment\n",
    "\n",
    "- [ ] **E.1 Monitoring and evaluation**: Not applicable; no model deployment.\n",
    "\n",
    "- [ ] **E.2 Redress**: Not applicable; no deployed system that could harm users.\n",
    "\n",
    "- [ ] **E.3 Roll back**: Not applicable; no deployment.\n",
    "\n",
    "- [ ] **E.4 Unintended use**: Not applicable; no deployed model.\n",
    "\n",
    "**Summary:** Overall, the project acknowledges ethical concerns regarding public data use, privacy, bias, and honest reporting. We have taken steps to minimize potential harm by focusing on aggregate trends rather than individual users, maintaining data security, and committing to transparent and honest analysis. The primary ethical considerations involve informed consent (users may not have anticipated research use) and selection bias (the dataset may not represent all ChatGPT users), both of which we will explicitly acknowledge in our findings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Communication and Responsiveness:** Each team member will check and respond to messages on our agreed communication platform within 24 hours on weekdays. Important decisions will be discussed collectively in scheduled meetings.\n",
    "\n",
    "* **Respectful Collaboration:** Team members will provide constructive feedback respectfully, even when disagreeing. Conflicts will be addressed immediately via discussion, not ignored.\n",
    "\n",
    "* **Responsibility and Accountability:** Everyone is responsible for completing their assigned tasks by agreed deadlines. If a team member cannot meet a deadline, they will notify the team in advance and propose a solution.\n",
    "\n",
    "* **Documentation and Transparency:** All code, analysis, and notes will be shared in a central repository with clear version control. Any assumptions, decisions, or changes to methods will be recorded for transparency.\n",
    "\n",
    "* **Mutual Support and Learning:** Team members will assist one another in understanding methods, tools, or concepts as needed. We encourage knowledge sharing to ensure all members can contribute meaningfully to the project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date | Meeting Time | Completed Before Meeting | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/28 | 6 PM | Read COGS 108 expectations; review project requirements | Finalize communication channels; confirm research question and hypothesis; assign initial background research tasks |\n",
    "| 2/3 | 6 PM | Complete assigned background research; identify potential datasets | Review background research; discuss WildChat dataset access and structure; draft ethics considerations |\n",
    "| 2/4 | 6 PM | Finalize and review proposal draft | Submit project proposal; discuss data download and initial exploration plan; assign data wrangling tasks |\n",
    "| 2/11 | 6 PM | Download WildChat dataset; explore data structure | Review data characteristics; plan preprocessing pipeline (filtering by date, removing system messages, handling missing data) |\n",
    "| 2/14 | 6 PM | Complete data wrangling and cleaning; perform initial EDA | Review wrangling/EDA; finalize approach for topic modeling and sentiment analysis; assign analysis tasks |\n",
    "| 2/25 | 6 PM | Implement topic modeling (e.g., LDA) and sentiment analysis | Review analysis results; refine categorization of prompt types; complete project check-in |\n",
    "| 3/6 | 6 PM | Conduct temporal analysis of prompt type distribution | Discuss findings; create visualizations; begin drafting results and discussion sections |\n",
    "| 3/13 | 6 PM | Complete analysis; draft results, conclusion, and discussion | Review and edit full project; address any remaining limitations or ethical considerations |\n",
    "| 3/20 | Before 11:59 PM | Finalize all sections; proofread | Submit Final Project & Group Project Surveys |\n",
    "\n",
    "**Special Resources/Training Needed:** This project will require use of natural language processing libraries such as scikit-learn or gensim for topic modeling (LDA or similar), and NLTK or TextBlob for sentiment analysis. Team members unfamiliar with these tools will review relevant COGS 108 materials and online tutorials (e.g., scikit-learn documentation, topic modeling guides) before the analysis phase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
